{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Solution to Burger's Equation\n",
    "\n",
    "$$\n",
    "\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x} = \\nu \\frac{\\partial^2 u}{\\partial x^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#import tensorflow.compat.v1 as tf\n",
    "#tf.disable_v2_behavior() \n",
    "import time\n",
    "\n",
    "#Imports for visualization\n",
    "import PIL.Image\n",
    "from io import BytesIO\n",
    "from IPython.display import clear_output, Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DisplayArray(a, fmt='jpeg', rng=[0,1]):\n",
    "    \"\"\"Display an array as a picture.\"\"\"\n",
    "    a = (a - rng[0])/float(rng[1] - rng[0])*255\n",
    "    a = np.uint8(np.clip(a, 0, 255))\n",
    "    f = BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    clear_output(wait = True)\n",
    "    display(Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_NN(self, layers):        \n",
    "    weights = []\n",
    "    biases = []\n",
    "    num_layers = len(layers) \n",
    "    for l in range(0,num_layers-1):\n",
    "        W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
    "        b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
    "        weights.append(W)\n",
    "        biases.append(b)        \n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]        \n",
    "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
    "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net(self, X, weights, biases):\n",
    "        num_layers = len(weights) + 1\n",
    "        \n",
    "        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n",
    "        for l in range(0,num_layers-2):\n",
    "            W = weights[l]\n",
    "            b = biases[l]\n",
    "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
    "        W = weights[-1]\n",
    "        b = biases[-1]\n",
    "        Y = tf.add(tf.matmul(H, W), b)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_gradients_0(self, U, x):        \n",
    "        g = tf.gradients(U, x, grad_ys=self.dummy_x0_tf)[0]\n",
    "        return tf.gradients(g, self.dummy_x0_tf)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_gradients_1(self, U, x):        \n",
    "        g = tf.gradients(U, x, grad_ys=self.dummy_x1_tf)[0]\n",
    "        return tf.gradients(g, self.dummy_x1_tf)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_U0(self, x):\n",
    "        U1 = self.neural_net(x, self.weights, self.biases)\n",
    "        U = U1[:,:-1]\n",
    "        U_x = self.fwd_gradients_0(U, x)\n",
    "        U_xx = self.fwd_gradients_0(U_x, x)\n",
    "        F = 5.0*U - 5.0*U**3 + 0.0001*U_xx\n",
    "        U0 = U1 - self.dt*tf.matmul(F, self.IRK_weights.T)\n",
    "        return U0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_U1(self, x):\n",
    "        U1 = self.neural_net(x, self.weights, self.biases)\n",
    "        U1_x = self.fwd_gradients_1(U1, x)\n",
    "        return U1, U1_x # N x (q+1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(self, loss):\n",
    "        print('Loss:', loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, nIter):\n",
    "        tf_dict = {self.x0_tf: self.x0, self.u0_tf: self.u0, self.x1_tf: self.x1,\n",
    "                   self.dummy_x0_tf: np.ones((self.x0.shape[0], self.q)),\n",
    "                   self.dummy_x1_tf: np.ones((self.x1.shape[0], self.q+1))}\n",
    "        \n",
    "        start_time = time.time()\n",
    "        for it in range(nIter):\n",
    "            self.sess.run(self.train_op_Adam, tf_dict)\n",
    "            \n",
    "            # Print\n",
    "            if it % 10 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                loss_value = self.sess.run(self.loss, tf_dict)\n",
    "                print('It: %d, Loss: %.3e, Time: %.2f' % \n",
    "                      (it, loss_value, elapsed))\n",
    "                start_time = time.time()\n",
    "    \n",
    "        self.optimizer.minimize(self.sess,\n",
    "                                feed_dict = tf_dict,\n",
    "                                fetches = [self.loss],\n",
    "                                loss_callback = self.callback)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, x_star):\n",
    "        \n",
    "        U1_star = self.sess.run(self.U1_pred, {self.x1_tf: x_star})\n",
    "                    \n",
    "        return U1_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u(t, x):\n",
    "    u = neural_net(tf.concat([t,x],1), weights, biases)\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(t, x):\n",
    "    u = u(t, x)\n",
    "    u_t = tf.gradients(u, t)[0]\n",
    "    u_x = tf.gradients(u, x)[0]\n",
    "    u_xx = tf.gradients(u_x, x)[0]\n",
    "    f = u_t + u*u_x - (0.01/tf.pi)*u_xx\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.lb = lb\n",
    "        self.ub = ub\n",
    "        \n",
    "        self.x0 = x0\n",
    "        self.x1 = x1\n",
    "        \n",
    "        self.u0 = u0\n",
    "        \n",
    "        self.layers = layers\n",
    "        self.dt = dt\n",
    "        self.q = max(q,1)\n",
    "    \n",
    "        # Initialize NN\n",
    "        self.weights, self.biases = self.initialize_NN(layers)\n",
    "        \n",
    "        # Load IRK weights\n",
    "        tmp = np.float32(np.loadtxt('../../Utilities/IRK_weights/Butcher_IRK%d.txt' % (q), ndmin = 2))\n",
    "        self.IRK_weights = np.reshape(tmp[0:q**2+q], (q+1,q))\n",
    "        self.IRK_times = tmp[q**2+q:]\n",
    "        \n",
    "        # tf placeholders and graph\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
    "                                                     log_device_placement=True))\n",
    "        \n",
    "        self.x0_tf = tf.placeholder(tf.float32, shape=(None, self.x0.shape[1]))\n",
    "        self.x1_tf = tf.placeholder(tf.float32, shape=(None, self.x1.shape[1]))\n",
    "        self.u0_tf = tf.placeholder(tf.float32, shape=(None, self.u0.shape[1]))\n",
    "        self.dummy_x0_tf = tf.placeholder(tf.float32, shape=(None, self.q)) # dummy variable for fwd_gradients\n",
    "        self.dummy_x1_tf = tf.placeholder(tf.float32, shape=(None, self.q+1)) # dummy variable for fwd_gradients\n",
    "        \n",
    "        self.U0_pred = self.net_U0(self.x0_tf) # N x (q+1)\n",
    "        self.U1_pred, self.U1_x_pred= self.net_U1(self.x1_tf) # N1 x (q+1)\n",
    "        \n",
    "        self.loss = tf.reduce_sum(tf.square(self.u0_tf - self.U0_pred)) + \\\n",
    "                    tf.reduce_sum(tf.square(self.U1_pred[0,:] - self.U1_pred[1,:])) + \\\n",
    "                    tf.reduce_sum(tf.square(self.U1_x_pred[0,:] - self.U1_x_pred[1,:]))                     \n",
    "        \n",
    "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \n",
    "                                                                method = 'L-BFGS-B', \n",
    "                                                                options = {'maxiter': 50000,\n",
    "                                                                           'maxfun': 50000,\n",
    "                                                                           'maxcor': 50,\n",
    "                                                                           'maxls': 50,\n",
    "                                                                           'ftol' : 1.0 * np.finfo(float).eps})\n",
    "        \n",
    "        self.optimizer_Adam = tf.train.AdamOptimizer()\n",
    "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'neural_net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-142443d2ff49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mu_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-4630cb564e24>\u001b[0m in \u001b[0;36mu\u001b[0;34m(t, x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneural_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'neural_net' is not defined"
     ]
    }
   ],
   "source": [
    "N = 100 \n",
    "steps = 100\n",
    "    \n",
    "# Doman bounds\n",
    "t = np.linspace(0,1,steps)\n",
    "x = np.linspace(-1,1,N)\n",
    "\n",
    "u_init = u(x,t)\n",
    "print(u_init)\n",
    "\n",
    "u_init[0,:] = - np.sin(np.pi*x)\n",
    "\n",
    "u_init[:,0] = 0\n",
    "u_init[:,N-1] = 0\n",
    "\n",
    "\n",
    "print(u_init)\n",
    "\n",
    "DisplayArray(u_init, rng=[-1.0, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "# eps -- time resolution\n",
    "# damping -- wave damping\n",
    "# c -- wave speed \n",
    "eps = tf.placeholder(tf.float32, shape=())\n",
    "damping = tf.placeholder(tf.float32, shape=())\n",
    "c = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "# Create variables for simulation state\n",
    "U  = tf.Variable(u_init)\n",
    "Ut = tf.Variable(ut_init)\n",
    "\n",
    "# Discretized PDE update rules\n",
    "U_ = U + eps * Ut\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
